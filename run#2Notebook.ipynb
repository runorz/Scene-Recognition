{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVC3#2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5df-jL9MCS7",
        "colab_type": "code",
        "outputId": "adaac182-078d-4a30-a357-367dc44a3697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SibHteECkCg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image: np.ndarray, only accept 2-D grayscale image with shape in 2 dimension\n",
        "#step: how many pizels the patch move\n",
        "#patch_size: the size of the patch\n",
        "#return the array with all the features, with shape (feature_amount, patch_size * patch_size)\n",
        "def extractFeaturesFromImage(image, step, patch_size):\n",
        "  width = image.shape[0]\n",
        "  height = image.shape[1]\n",
        "  features = []\n",
        "  for y in range(0, height, step):\n",
        "    if height - y < patch_size:\n",
        "      break\n",
        "    for x in range(0, width, step):\n",
        "      if width - x < patch_size:\n",
        "        break\n",
        "      features.append(np.concatenate(image[x: x+patch_size, y: y+patch_size]))\n",
        "  return np.asarray(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZctPfskapVvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image_features: the features array from images, should be done zero-mean and unit variace with the features from extractFeaturesFromImage()\n",
        "#trained_KMeans: the KMeans model that has been trained, which will return the centers each feature belongs to, while input the features\n",
        "def quantisation(image_features, trained_KMeans):\n",
        "  n_centers = trained_KMeans.cluster_centers_.shape[0]\n",
        "  visual_words_hist = np.zeros(n_centers)\n",
        "  predictions = trained_KMeans.predict(image_features)\n",
        "  for index in predictions:\n",
        "    visual_words_hist[index] = visual_words_hist[index] + 1\n",
        "  return visual_words_hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvhK2zRJJB7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "#The directory where training and testing directory were set\n",
        "directory = \"/content/drive/My Drive/\"\n",
        "\n",
        "train_directory = directory + \"training/\"\n",
        "test_directory = directory + \"testing/\"\n",
        "\n",
        "#All the class lebel, this is a List variable\n",
        "labels = os.listdir(train_directory)\n",
        "\n",
        "step = 4\n",
        "\n",
        "patch_size = 8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvSomSHXgudL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_features = []\n",
        "\n",
        "train_target = []\n",
        "\n",
        "#Load all images but only store their features on a list\n",
        "for index in range(len(labels)):\n",
        "  for name in os.listdir(train_directory + labels[index] + \"/\"):\n",
        "    train_images_features.append(extractFeaturesFromImage(cv2.imread(train_directory + labels[index] + \"/\" + name, cv2.IMREAD_GRAYSCALE), step, patch_size))\n",
        "    train_target.append(index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c5EU3-Vg3S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#It takes 5-10 minutes to run KMeans for k = 1000\n",
        "k = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP9H0NuDg3NN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#Do zero-mean and unit variace to the all training features array\n",
        "scaled_train_images_features = preprocessing.scale(np.concatenate(train_images_features))\n",
        "\n",
        "#Record the parameter used for cluster scaling, then use it to scale test data\n",
        "scaler_for_clustering = preprocessing.StandardScaler().fit(np.concatenate(train_images_features))\n",
        "\n",
        "#KMeans clustering\n",
        "kmeans = MiniBatchKMeans(k, init_size=3*k).fit(scaled_train_images_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU1UFXw0huaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_visual_word_hists = []\n",
        "\n",
        "#quntisation every image\n",
        "for one_image_features in train_images_features:\n",
        "  train_visual_word_hists.append(quantisation(scaler_for_clustering.transform(one_image_features), kmeans))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u54gKuT7hzk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Do zero-mean and unit variance to the visual word histogram\n",
        "scaled_train_visual_word_hists = preprocessing.scale(np.asarray(train_visual_word_hists))\n",
        "\n",
        "#Record the parameter used for classification scaling, then use it to scale test data\n",
        "scaler_for_classification = preprocessing.StandardScaler().fit(np.asarray(train_visual_word_hists))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRd86oLSjaRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a971b5a8-16f9-452f-cac0-6034701407d6"
      },
      "source": [
        "scaled_train_visual_word_hists.shape"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_09ongxh7ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "clf = OneVsOneClassifier(LinearSVC(max_iter=20000)).fit(scaled_train_visual_word_hists, np.asarray(train_target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aCxwOU6hl8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"run2.txt\", \"w+\")\n",
        "\n",
        "#Used trained classifier to predict the class of images in testset and write it into text file\n",
        "#This takes longer time than loading training image, about 5-10 minutes\n",
        "for name in os.listdir(test_directory):\n",
        "  test_image = cv2.imread(test_directory+name, cv2.IMREAD_GRAYSCALE)\n",
        "  test_image_features = extractFeaturesFromImage(test_image, step, patch_size)\n",
        "  scaled_test_image_features = scaler_for_clustering.transform(test_image_features)\n",
        "  test_image_hist = quantisation(scaled_test_image_features, kmeans)\n",
        "  test_image_hist = test_image_hist.reshape(1,k)\n",
        "  scaled_test_image_hist = scaler_for_classification.transform(test_image_hist)\n",
        "  predicted_class = clf.predict(scaled_test_image_hist)\n",
        "  f.write(name+\" \"+labels[int(predicted_class[0])]+\"\\n\")\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8lGdHZkgqdu",
        "colab_type": "text"
      },
      "source": [
        "### From here it is for analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dO22mi4LdXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images_features = []\n",
        "validation_images_features = []\n",
        "\n",
        "train_target = []\n",
        "validation_target = []\n",
        "\n",
        "val_ratio = 20\n",
        "\n",
        "for index in range(len(labels)):\n",
        "  count = 0\n",
        "  for name in os.listdir(train_directory + labels[index] + \"/\"):\n",
        "    if count < 20:\n",
        "      validation_images_features.append(extractFeaturesFromImage(cv2.imread(train_directory + labels[index] + \"/\" + name, cv2.IMREAD_GRAYSCALE), step, patch_size))\n",
        "      validation_target.append(index)\n",
        "    else:\n",
        "      train_images_features.append(extractFeaturesFromImage(cv2.imread(train_directory + labels[index] + \"/\" + name, cv2.IMREAD_GRAYSCALE), step, patch_size))\n",
        "      train_target.append(index)\n",
        "    count = count + 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LYxycjKewFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 700"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3B7rEdmSCrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "scaled_train_images_features = preprocessing.scale(np.concatenate(train_images_features))\n",
        "\n",
        "scaler_for_clustering = preprocessing.StandardScaler().fit(np.concatenate(train_images_features))\n",
        "\n",
        "kmeans = MiniBatchKMeans(k, init_size=3*k).fit(scaled_train_images_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbwQd-SxXLSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_visual_word_hists = []\n",
        "\n",
        "for one_image_features in train_images_features:\n",
        "  train_visual_word_hists.append(quantisation(scaler_for_clustering.transform(one_image_features), kmeans))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEJrJ6TSaWfZ",
        "colab_type": "code",
        "outputId": "174f472e-59ff-4511-ad3d-82152d847edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.asarray(train_visual_word_hists).shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 700)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkLxkBF3Z2p4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_train_visual_word_hists = preprocessing.scale(np.asarray(train_visual_word_hists))\n",
        "\n",
        "scaler_for_classification = preprocessing.StandardScaler().fit(np.asarray(train_visual_word_hists))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGaHNWAscVO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_visual_word_hists = []\n",
        "\n",
        "for one_image_features in validation_images_features:\n",
        "  test_visual_word_hists.append(quantisation(scaler_for_clustering.transform(one_image_features), kmeans))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ISYEm4vdrOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_test_visual_word_hists = scaler_for_classification.transform(np.asarray(test_visual_word_hists))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO8hjz4IbjvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "clf = OneVsOneClassifier(LinearSVC(max_iter=20000)).fit(scaled_train_visual_word_hists, np.asarray(train_target))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6hwIRBnd_-z",
        "colab_type": "code",
        "outputId": "d9531d76-7a8e-484c-8954-c84d8e368fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.score(scaled_test_visual_word_hists, np.asarray(validation_target))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5966666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    }
  ]
}